--------------------------------------------------------------------------------------------------------------------------------------
---------------------------------------------------------- 第1章 Kubernetes 简介 ------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------
为什么会有 Kubernetes?
    什么是云计算? 参考 01_云计算的定义.png
    Docker 的流行和标准化 激活了 PaaS, Kubernetes是 PaaS 的最佳代表!

Kubernetes 是什么?
    Kubernetes 在古希腊语中是 舵手 的意思
    Kubernetes 是 Google 开源容器集群管理系统

Kubernetes 的核心概念:
    Pod:
        在 Kubernetes 中的 同一台宿主机中的 docker 容器, 共享宿主机的容器卷, docker 之间共享一个 网络命名空间, IP地址和端口, 可以通过 localhost 来发现对方!
        Pod 是 Kubernetes 中的最小管理单元!

    Replication Controller:
        用来控制 Kubernetes 集群中的 Pod副本数量, 如果少于 指定数量的 Pod 副本, 则启动新的 Pod 副本, 如果多于 指定数量的 Pod 副本, 则杀死多余的 Pod 副本;

    Service:
        定义 Pod 的逻辑集合 和 访问这个 Pod 集合的策略, Service 将代理 Pod 对外访问 抽象化!

    Label:
        Label 是 Replication Controller 和 Service 的基础, 他们都通过 Label 来关联 Pod!

    Node:
        Kubernetes 集群采用 主从 方式部署! Kubernetes Node 简称 Node, Pod 最终运行在 Node 上, 可以认为 Node 是 Pod 的宿主机!


--------------------------------------------------------------------------------------------------------------------------------------
---------------------------------------------------------- 第2章 Kubernetes 架构与部署 -------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------
Kubernetes 集群是采用 主从模式进行架构的! 分为 Master 节点 和 Node 节点, 使用 Etcd 作为 配置存储中心!

安装过程参考: kubernetes安装.txt


--------------------------------------------------------------------------------------------------------------------------------------
---------------------------------------------------------- 第3章 Kubernetes 快速入门 ---------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------
使用  k8s-master 和 k8s-node-* 节点测试:

    kubernetes 使用环境:
    [root@k8s-master ~]# kubectl cluster-info
    Kubernetes master is running at https://192.168.188.44:6443
    KubeDNS is running at https://192.168.188.44:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

    [root@k8s-master ~]# kubectl get componentstatus
    NAME                 STATUS    MESSAGE             ERROR
    scheduler            Healthy   ok
    controller-manager   Healthy   ok
    etcd-0               Healthy   {"health":"true"}

    [root@k8s-master ~]# kubectl get nodes
    NAME         STATUS   ROLES    AGE     VERSION
    k8s-master   Ready    master   20h     v1.14.0
    k8s-node-1   Ready    <none>   3h41m   v1.14.0
    k8s-node-2   Ready    <none>   3h24m   v1.14.0
    k8s-node-3   Ready    <none>   3h24m   v1.14.0

运行 redis

    创建 Redis Master Pod
        1、创建文件 redis-master-controller.yaml

        2、通过定义文件 创建 Redis Master Replication Controller
            kubectl create -f /home/chapter_03/redis-master-controller.yaml
            kubectl delete -f /home/chapter_03/redis-master-controller.yaml

        3、创建成功后可查询 Redis Master Replication Controller
            [root@k8s-master ~]# kubectl get replicationcontroller redis-master
            NAME           DESIRED   CURRENT   READY   AGE
            redis-master   1         1         1       2m36s

        4、Redis Master Replication Controller 将会创建1个 Redis Master Pod, 创建出来的 Pod 就会 带上Label name=redis-master
            [root@k8s-master ~]# kubectl get pod --selector name=redis-master
            NAME                 READY   STATUS    RESTARTS   AGE
            redis-master-ntksz   1/1     Running   0          3m7s

    创建 Redis Master Service 代理 Redis Master Pod
        1、创建文件 redis-master-service.yaml

        2、通过 定义文件 创建 Redis Master Service
            kubectl create -f /home/chapter_03/redis-master-service.yaml
            kubectl delete -f /home/chapter_03/redis-master-service.yaml

        3、创建成功后可查询 Redis Master Service
            kubectl get service redis-master

    创建 Redis Slave Pod
        1、创建文件 redis-slave-controller.yaml

        2、通过定义文件 创建 Redis Slave Replication Controller
            kubectl create -f /home/chapter_03/redis-slave-controller.yaml
            kubectl delete -f /home/chapter_03/redis-slave-controller.yaml

        3、创建成功后可查询 Redis Slave Replication Controller
            [root@k8s-master ~]# kubectl get replicationcontroller redis-slave
            NAME          DESIRED   CURRENT   READY   AGE
            redis-slave   2         2         2       99s

        4、Redis Slave Replication Controller 将会创建1个 Redis Master Pod, 创建出来的 Pod 就会 带上Label name=redis-master
            [root@k8s-master ~]# kubectl get pod --selector name=redis-slave
            NAME                READY   STATUS    RESTARTS   AGE
            redis-slave-cwd9x   1/1     Running   0          119s
            redis-slave-r7n4p   1/1     Running   0          119s

    创建 Redis Slave Service
        1、创建文件 redis-slave-service.yaml

        2、通过 定义文件 创建 Redis Slave Service
            kubectl create -f /home/chapter_03/redis-slave-service.yaml
            kubectl delete -f /home/chapter_03/redis-slave-service.yaml

        3、创建成功后可查询 Redis Slave Service
            kubectl get service redis-slave

运行 Frontend

    创建 Frontend Pod
        1、创建文件 frontend-controller.yaml

        2、通过定义文件 创建 Frontend Replication Controller
            kubectl create -f /home/chapter_03/frontend-controller.yaml
            kubectl delete -f /home/chapter_03/frontend-controller.yaml

        3、创建成功后可查询 Frontend Replication Controller
            [root@k8s-master ~]# kubectl get replicationcontroller frontend
            NAME       DESIRED   CURRENT   READY   AGE
            frontend   3         3         3       3m27s

        4、Frontend Replication Controller 将会创建1个 Frontend Pod, 创建出来的 Pod 就会 带上Label name=frontend
            [root@k8s-master ~]# kubectl get pod --selector name=frontend
            NAME             READY   STATUS    RESTARTS   AGE
            frontend-fwg4p   1/1     Running   0          3m41s
            frontend-mqrlg   1/1     Running   0          3m41s
            frontend-tgdst   1/1     Running   0          3m41s

    创建 Frontend Service
        1、创建文件 frontend-service.yaml

        2、通过 定义文件 创建 Frontend Service
            kubectl create -f /home/chapter_03/frontend-service.yaml
            kubectl delete -f /home/chapter_03/frontend-service.yaml

        3、创建成功后可查询 Frontend Service
            [root@k8s-master ~]# kubectl get service frontend
            NAME       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
            frontend   ClusterIP   10.110.82.88   <none>        80/TCP    2m18s

设置 Guestbook 外网访问
    修改 frontend-service.yaml 添加
    spec:
      type: NodePort # 添加本行类型

    kubectl replace -f /home/chapter_03/frontend-service.yaml --force

    http://192.168.188.44:31505
    http://192.168.188.46:31505
    http://192.168.188.47:31505
    http://192.168.188.48:31505

    kubectl logs frontend-qkmhm


清理 replicationcontroller 和 service

    [root@k8s-master ~]# kubectl get pods
    NAME                 READY   STATUS    RESTARTS   AGE
    frontend-fwg4p       1/1     Running   0          58m
    frontend-mqrlg       1/1     Running   0          58m
    frontend-tgdst       1/1     Running   0          58m
    redis-master-fhhfp   1/1     Running   0          60m
    redis-slave-qpd65    1/1     Running   0          59m
    redis-slave-ssg4l    1/1     Running   0          59m


    [root@k8s-master ~]# kubectl get service
    NAME           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
    frontend       NodePort    10.98.33.24     <none>        80:31505/TCP   35m
    kubernetes     ClusterIP   10.96.0.1       <none>        443/TCP        24h
    redis-master   ClusterIP   10.102.167.37   <none>        6379/TCP       59m
    redis-slave    ClusterIP   10.96.72.37     <none>        6379/TCP       59m

    清除 replicationcontroller
    kubectl delete replicationcontroller redis-master redis-slave frontend

    清除 service
    kubectl delete service redis-master redis-slave frontend


--------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------ 第4章 Pod ---------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------
Hello World Pod 案例:
    1、创建文件 hello-world-pod.yaml

    2、通过定义文件 创建 Pod
      kubectl create -f /home/chapter_04/hello-world-pod.yaml
      kubectl delete -f /home/chapter_04/hello-world-pod.yaml

    3、查询 Pod
      [root@k8s-master ~]# kubectl get pod hello-world

    4、查询 Pod 输出的日志
      [root@k8s-master ~]# kubectl logs hello-world
      Hello World

    5、删除 Pod
      [root@k8s-master ~]# kubectl delete pod hello-world
      pod "hello-world" deleted

    核心: 就是搞了一个  centos:7 的 docker 镜像, 然后启动一个 基于此镜像的容器!

Pod 的基本操作:

    创建 Pod:

        使用命令: kubectl create -f *.yaml 文件创建

        使用错误案例: 使用 error-pod.yaml 创建!

        1、创建文件 error-pod.yaml

        2、通过定义文件 创建 Pod
          kubectl create -f /home/chapter_04/error-pod.yaml

        错误提示:
        [root@k8s-master ~]# kubectl create -f /home/chapter_04/error-pod.yaml
        The Pod "" is invalid:
        * metadata.name: Required value: name or generateName is required
        * spec.restartPolicy: Unsupported value: "Maybe": supported values: "Always", "OnFailure", "Never"

        这里提示 重启策略 只能 有3种策略值: Always, OnFailure, Never

    查询 Pod:

        查询指定 Pod:
        kubectl get pod hello-world
        kubectl get pod hello-world -o wide

        查询 Pod 的详细信息:
        kubectl get pod hello-world --output json    # 用 json 格式显示 Pod 的完整信息
        kubectl get pod hello-world --output yaml    # 用 yaml 格式显示 Pod 的完整信息

        查询 Pod 的状态 和 生命周期事件:
        [root@k8s-master ~]# kubectl describe pod hello-world
        Name:               hello-world
        Namespace:          default
        Priority:           0
        PriorityClassName:  <none>
        Node:               k8s-node-1/192.168.188.46
        Start Time:         Mon, 30 May 2022 15:51:01 +0800
        Labels:             <none>
        Annotations:        <none>
        Status:             Succeeded
        IP:                 10.32.0.4
        Containers:
          hello-world:
            Container ID:  docker://ed81005cab259505a8e54733ac2af9bce36fa80cc9ef53001e6b85bf3d6bb09b
            Image:         centos:7
            Image ID:      docker-pullable://centos@sha256:9d4bcbbb213dfd745b58be38b13b996ebb5ac315fe75711bd618426a630e0987
            Port:          <none>
            Host Port:     <none>
            Command:
              /bin/echo
              Hello
              World
            State:          Terminated
              Reason:       Completed
              Exit Code:    0
              Started:      Mon, 30 May 2022 15:51:28 +0800
              Finished:     Mon, 30 May 2022 15:51:28 +0800
            Ready:          False
            Restart Count:  0
            Environment:    <none>
            Mounts:
              /var/run/secrets/kubernetes.io/serviceaccount from default-token-v5l7t (ro)
        Conditions:
          Type              Status
          Initialized       True
          Ready             False
          ContainersReady   False
          PodScheduled      True
        Volumes:
          default-token-v5l7t:
            Type:        Secret (a volume populated by a Secret)
            SecretName:  default-token-v5l7t
            Optional:    false
        QoS Class:       BestEffort
        Node-Selectors:  <none>
        Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                         node.kubernetes.io/unreachable:NoExecute for 300s
        Events:
          Type    Reason          Age    From                 Message
          ----    ------          ----   ----                 -------
          Normal  Scheduled       3m13s  default-scheduler    Successfully assigned default/hello-world to k8s-node-1
          Normal  Pulling         3m12s  kubelet, k8s-node-1  Pulling image "centos:7"
          Normal  Pulled          2m46s  kubelet, k8s-node-1  Successfully pulled image "centos:7"
          Normal  Created         2m46s  kubelet, k8s-node-1  Created container hello-world
          Normal  Started         2m45s  kubelet, k8s-node-1  Started container hello-world
          Normal  SandboxChanged  2m44s  kubelet, k8s-node-1  Pod sandbox changed, it will be killed and re-created.

    删除 Pod:

        删除指令的 Pod:
        kubectl delete pod pod名称

        删除所有的 Pod:
        kubectl delete pod --all

    更新 Pod:
        使用格式: kubectl replace -f *.yaml


Pod 与 容器

    Linux 提供了 6 种 Namespace 隔离的系统调用, 参考 01_linux_namesapce隔离类型

    kubernetes 中 容器卷的共享 是基于 Pod 的, 而不是基于容器的!

    Pod 可以设置环境变量:
        格式:
        env:
        - name: PARAM_1
          value: VALUE_1
        - name: PARAM_2
          value: VALUE_2

        举例:
        env:
        - name: MESSAGE
          value: "hello world"
        command: ["/bin/sh", "-c"]
        args: ["/bin/echo \"${MESSAGE}\""]

        修改后可以 测试一下 hello-world-pod.yaml 的使用方式!

        通过环境变量获取 Downward API, 定义文件 downwardapi-env.yaml
            [root@k8s-master ~]# kubectl exec downwardapi-env env|grep MY_POD
            MY_POD_NAME=downwardapi-env
            MY_POD_NAMESPACE=default
            MY_POD_IP=10.32.0.2

    数据持久化和共享
        容器是临时存在的, 如果容器被销毁, 容器中的数据将会丢失! 容器提出了容器卷或者共享数据卷的概念!

        docker 中的数据卷是 容器级别的, kubernetes 中的数据卷是 Pod 级别的! 即 Pod 内所有的容器共享 相同的数据卷, 实现 同一个 Pod 之内的数据共享!

        对 hello-world-pod.yaml 再次进行改造, 实现 pod 数据卷!


Pod 的网络:
    [root@k8s-master ~]# kubectl get pod hello-world --template={{.status.podIP}}
    10.40.0.1

    设置 network 为 host 类型的 案例, 参考 nginx-network-host.yaml
    测试结果为:
    [root@k8s-master ~]# kubectl get pod my-app --template={{.status.podIP}}
    192.168.188.47

Pod 的重启策略:
    restartPolicy 有三种可选项: Always, OnFailure, Never

Pod 的状态和声明周期

    容器状态 STATUS
    192.168.188.47[root@k8s-master ~]# kubectl get pod
    NAME          READY   STATUS      RESTARTS   AGE
    hello-world   0/2     Completed   0          86m
    my-app        1/1     Running     0          10m

    查询 Pod 详细信息
    kubectl describe pod hello-world

    查询 容器生命周期 处在哪个阶段:
    kubectl get pods hello-world --template={{.status.phase}}

自定义 Pod 检查:
    当 Pod 已经运行时并不能代表 当前 Pod 就可以接收请求, 可能处于阻塞状态!

    kubernetes 提供了两种检查: 健康检查 (Liveness Probe)和 准备检查 (Readiness Probe)!
    并且用三种命令 配合使用 ExecAtion, TCPSocketAction, HTTPGetAction!

    ExecAtion
        当命令执行成功(返回码为0), 检查成功!

        示例:
        exec:
            command:
            - cat
            - /tmp/health

    TCPSocketAction:
        当容器中的TCP端口被占用, 表示成功

        示例:
        tcpSocket:
            port: 8080


    HTTPGetAction:
        当响应码 介于 200 ~ 400 之间时, 检查成功!

        配置参数:
            path: 请求 URI 路径, 可选项
            port: 请求 端口
            host: 请求 IP, 默认为 Pod 的 podIP
            scheme: 请求协议, 默认为 HTTP

        示例:
        httpGet:
            path: /healthz
            port: 8080


    健康检查具体案例:
        1、创建 liveness-exec-pod.yaml

        2、执行 创建 pod
          kubectl create -f /home/chapter_04/liveness-exec-pod.yaml

        3、查询 pod 事件, 可以看到 Liveness Probe 检查失败
        [root@k8s-master ~]# kubectl describe pod liveness-exec-pod | grep Unhealthy
        Warning  Unhealthy  13m (x130 over 3h12m)   kubelet, k8s-node-3  Liveness probe failed: cat: /tmp/health: No such file or directory

    准备检查具体案例:
        1、创建 readiness-exec-pod.yaml

        2、执行 创建 pod
        kubectl create -f /home/chapter_04/readiness-exec-pod.yaml

        3、查询 pod 事件, 可以看到 Liveness Probe 检查失败
        [root@k8s-master ~]# kubectl describe pod readiness-exec-pod | grep Unhealthy


调度 pod:
    将 pod 发布到指定的 node 节点中, 这里只介绍一种 nodeName 属性! (不推荐使用, 因为 kubernetes 自动调度算法技术 已经 非常成熟了)

    举例案例:
        1、创建 nginx-pod-node.yaml 文件

        2、执行创建 pod
        kubectl create -f /home/chapter_04/nginx-pod-node.yaml

        3、查询 当前 pod 所在 node 节点 即为 nodeName: k8s-node-1
        [root@k8s-master ~]# kubectl get pod -o wide
        NAME                 READY   STATUS    RESTARTS   AGE   IP          NODE         NOMINATED NODE   READINESS GATES
        nginx-pod-node       1/1     Running   0          24s   10.32.0.2   k8s-node-1   <none>           <none>

Pod 日志查询:

    查看 pod 的详细信息指令: kubectl describe pod pod_name
    kubectl describe pod

    日志查询具体案例:
        1、创建 log-pod.yaml

        2、根据 yaml 文件 创建 pod

        3、查看日志
        [root@k8s-master ~]# kubectl get pod log-pod -o wide
        NAME      READY   STATUS      RESTARTS   AGE   IP          NODE         NOMINATED NODE   READINESS GATES
        log-pod   0/2     Completed   0          16s   10.34.0.1   k8s-node-3   <none>           <none>

        [root@k8s-master ~]# kubectl logs log-pod container1
        container1: 2022-05-31 19:01:07.944392455+00:00

        [root@k8s-master ~]# kubectl logs log-pod container2
        container2: 2022-05-31 19:01:08.175822603+00:00


kubernetes 进入 pod 容器:
    kubectl exec -it pod_name /bin/bash


--------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------- 第5章 Replication Controller -----------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------
ReplicationController 是 kubernetes 中的另一个核心概念! 它可以指定 Pod 的副本数量! 在此基础上又添加了新的功能如 弹性伸缩、滚动升级等!

持续运行的 Pod
    注意: pod 的 名称是以 replicationcontroller name 为前缀的一个名称! 后面5个字符为随机生成的字符串! 举例: my-nginx-42lrz

    具体案例:
    1、创建 文件 my-nginx-rc.yaml

    2、根据创建的文件 创建 replicationcontroller
        kubectl create -f /home/chapter_05/my-nginx-rc.yaml

    3、查看 replicationcontroller
        [root@k8s-master ~]# kubectl get replicationcontroller -o wide
        NAME       DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES   SELECTOR
        my-nginx   2         2         2       25s   nginx        nginx    app=my-nginx

    4、获取 Pod 相关信息
        [root@k8s-master ~]# kubectl get pods -o wide
        NAME             READY   STATUS    RESTARTS   AGE     IP          NODE         NOMINATED NODE   READINESS GATES
        my-nginx-42lrz   1/1     Running   0          2m23s   10.34.0.1   k8s-node-3   <none>           <none>
        my-nginx-5xrfg   1/1     Running   0          2m23s   10.32.0.2   k8s-node-1   <none>           <none>

    5、测试删除 pod 后, 是否会重新创建一个 保证 pod 运行副本的数量!
        kubectl delete pod my-nginx-42lrz

    6、删除 replicationcontroller 后 pod 也会随之删除
        kubectl delete replicationcontroller my-nginx

Pod 模板
    模板案例:
    1、创建 nginx-pod-template.yaml

    2、根据文件 创建 pod template
       kubectl create -f /home/chapter_05/nginx-pod-template.yaml

    3、查询 pod template
        [root@k8s-master ~]# kubectl get podtemplate
        NAME             CONTAINERS   IMAGES   POD LABELS
        nginx-template   nginx        nginx    app=nginx-template


Replication Controller 和 Pod 的关系:
    常用查询命令:
    [root@k8s-master ~]# kubectl get pods --selector name --label-columns=name,version
    NAME                 READY   STATUS    RESTARTS   AGE     NAME           VERSION
    mine-nginx-1-dcdlm   1/1     Running   0          3m37s   mine-nginx-4   v1
    mine-nginx-1-phcsf   1/1     Running   0          3m37s   mine-nginx-4   v1
    mine-nginx-1-tqkrm   1/1     Running   0          3m37s   mine-nginx-4   v1


    ReplicationController 通过 spec.selector 和 pod 的 labels 进行关联!

    具体案例:
        1、创建 replication 和 containers 具有不同的标签的 mine-nginx-rc.yaml


        2、根据文件 创建 replication controller
            kubectl create -f /home/chapter_05/mine-nginx-rc.yaml

            注意 replication controller 中的 spec.selector 标签 必须 和 template.metadata.labels 标签一致 key value 必须一致!
            否则报错:
            [root@k8s-master ~]# kubectl create -f /home/chapter_05/mine-nginx-rc.yaml
            The ReplicationController "mine-nginx-1" is invalid: spec.template.metadata.labels: Invalid value: map[string]string{"name":"mine-nginx-4", "version":"v1"}: `selector` does not match template `labels`

        3、查询相关pod
            [root@k8s-master ~]# kubectl get pods --selector name --label-columns=name
            NAME                 READY   STATUS    RESTARTS   AGE   NAME
            mine-nginx-1-db58r   1/1     Running   0          21s   mine-nginx-4
            mine-nginx-1-kcnvp   1/1     Running   0          21s   mine-nginx-4
            mine-nginx-1-kttwn   1/1     Running   0          21s   mine-nginx-4

        4、修改已经存在的 pod 的 标签, 举例: 修改 mine-nginx-1-db58r 的标签为 debug
            [root@k8s-master ~]# kubectl label pod mine-nginx-1-db58r name=debug --overwrite
            pod/mine-nginx-1-db58r labeled

            [root@k8s-master ~]# kubectl get pods --selector name --label-columns=name
            NAME                 READY   STATUS              RESTARTS   AGE     NAME
            mine-nginx-1-db58r   1/1     Running             0          4m39s   debug               # 标签已经变为 debug
            mine-nginx-1-df5zw   0/1     ContainerCreating   0          3s      mine-nginx-4        # 因为 replicationcontroller 要保证副本的数量, 所以重新创建了一个
            mine-nginx-1-kcnvp   1/1     Running             0          4m39s   mine-nginx-4
            mine-nginx-1-kttwn   1/1     Running             0          4m39s   mine-nginx-4


ReplicationController 的伸缩性:
    伸缩原理: 通过控制 pod 副本的数量来进行伸缩!

    具体案例:
        1、创建 replication controller 文件 nginx-scale-rc.yaml

        2、通过 文件创建 replication controller
            [root@k8s-master ~]# kubectl create -f /home/chapter_05/nginx-scale-rc.yaml
            replicationcontroller/nginx-scale created

        3、查看 pod , 主要观察 replicas 的数量
            [root@k8s-master ~]# kubectl get replicationcontroller
            NAME          DESIRED   CURRENT   READY   AGE
            nginx-scale   1         1         1       3s                # ready = 1 : 表示有1个 pod 副本

        4、扩容, 使副本的数量变为 3
            [root@k8s-master ~]# kubectl scale replicationcontroller nginx-scale --replicas=3
            replicationcontroller/nginx-scale scaled

            [root@k8s-master ~]# kubectl get replicationcontroller
            NAME          DESIRED   CURRENT   READY   AGE
            nginx-scale   3         3         3       4m14s             # ready = 3 : 表示有3个 pod 副本

        5、缩容, 使副本的数量变为1
            [root@k8s-master ~]# kubectl scale replicationcontroller nginx-scale --replicas=1
            replicationcontroller/nginx-scale scaled

自动伸缩: 了解一下!

滚动升级
    4个 version=1 的 pod, 滚动升级称为 4个 version=2 的 pod

    1、创建 文件 rolling-upgrade-v1.yaml

    2、根据文件 创建 replication controller
        kubectl create -f /home/chapter_05/rolling-upgrade-v1.yaml

    3、查询当前 详细信息
        [root@k8s-master ~]# kubectl get pods --selector name --label-columns=name,version
        NAME                  READY   STATUS    RESTARTS   AGE     NAME         VERSION
        mine-nginx-v1-bbf57   1/1     Running   0          2m35s   mine-nginx   v1
        mine-nginx-v1-d6lcn   1/1     Running   0          2m35s   mine-nginx   v1
        mine-nginx-v1-k8spz   1/1     Running   0          2m35s   mine-nginx   v1
        mine-nginx-v1-xwbl9   1/1     Running   0          2m35s   mine-nginx   v1

    4、升级准备: 创建 rolling-upgrade-v2.yaml

    5、执行滚动升级
        [root@k8s-master ~]# kubectl rolling-update mine-nginx-v1 -f /home/chapter_05/rolling-upgrade-v2.yaml --update-period=10s
        Command "rolling-update" is deprecated, use "rollout" instead
        Created mine-nginx-v2
        Scaling up mine-nginx-v2 from 0 to 4, scaling down mine-nginx-v1 from 4 to 0 (keep 4 pods available, don't exceed 5 pods)
        Scaling mine-nginx-v2 up to 1
        Scaling mine-nginx-v1 down to 3
        Scaling mine-nginx-v2 up to 2
        Scaling mine-nginx-v1 down to 2
        Scaling mine-nginx-v2 up to 3
        Scaling mine-nginx-v1 down to 1
        Scaling mine-nginx-v2 up to 4
        Scaling mine-nginx-v1 down to 0
        Update succeeded. Deleting old controller: mine-nginx-v1
        Renaming mine-nginx-v2 to mine-nginx-v1
        replicationcontroller/mine-nginx-v1 rolling updated

deployment: 了解这种 kind=Deployment

一次性任务的 pod:
    kind = Job

    举例:
    1、创建 计算 pi 的 yaml 文件, pi-job.yaml

    2、执行创建
        [root@k8s-master ~]# kubectl create -f /home/chapter_05/pi-job.yaml

        问题:
            The Job "pi-job" is invalid: spec.selector: Invalid value: v1.LabelSelector{MatchLabels:map[string]string{"controller-uid":"2b1a2f89-e1e2-11ec-8d1e-000c296c1229", "name":"pi-job"}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: `selector` not auto-generated

        解决:
            在 selector 上面添加一行!
            manualSelector: true          # 必须添加这行, 否则 job 创建失败

            [root@k8s-master ~]# kubectl create -f /home/chapter_05/pi-job.yaml
            job.batch/pi-job created

    3、执行相关的查看工作
        [root@k8s-master ~]# kubectl get pod                        # 只会执行一次, 这里显示是已经 完成的状态: completed
        NAME           READY   STATUS      RESTARTS   AGE
        pi-job-25x4z   0/1     Completed   0          2m3s

        [root@k8s-master ~]# kubectl logs pi-job-25x4z
        3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679821480865132823066470938446095505822317253594081284811174502841027019385211055596446229489549303819644288109756659334461284756482337867831652712019091456485669234603486104543266482133936072602491412737245870066063155881748815209209628292540917153643678925903600113305305488204665213841469519415116094330572703657595919530921861173819326117931051185480744623799627495673518857527248912279381830119491298336733624406566430860213949463952247371907021798609437027705392171762931767523846748184676694051320005681271452635608277857713427577896091736371787214684409012249534301465495853710507922796892589235420199561121290219608640344181598136297747713099605187072113499999983729780499510597317328160963185950244594553469083026425223082533446850352619311881710100031378387528865875332083814206171776691473035982534904287554687311595628638823537875937519577818577805321712268066130019278766111959092164201989380952572010654858632788659361533818279682303019520353018529689957736225994138912497217752834791315155748572424541506959508295331168617278558890750983817546374649393192550604009277016711390098488240128583616035637076601047101819429555961989467678374494482553797747268471040475346462080466842590694912933136770289891521047521620569660240580381501935112533824300355876402474964732639141992726042699227967823547816360093417216412199245863150302861829745557067498385054945885869269956909272107975093029553211653449872027559602364806654991198818347977535663698074265425278625518184175746728909777727938000816470600161452491921732172147723501414419735685481613611573525521334757418494684385233239073941433345477624168625189835694855620992192221842725502542568876717904946016534668049886272327917860857843838279679766814541009538837863609506800642251252051173929848960841284886269456042419652850222106611863067442786220391949450471237137869609563643719172874677646575739624138908658326459958133904780275901


--------------------------------------------------------------------------------------------------------------------------------------
---------------------------------------------------------------- 第6章 Service -------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------
Service 代理 Pod:
    Service 是一种服务的抽象, 它为关联的 Pod 提供一个固定的 IP 地址进行访问, Service 通过 Label 和 Pod 进行关联!

    创建 replication controller

        1、创建 replicationcontroller 文件  mine-nginx-rc.yaml

        2、根据文件创建 replicationcontroller
            [root@k8s-master ~]# kubectl create -f /home/chapter_06/mine-nginx-rc.yaml
            replicationcontroller/mine-nginx created

        3、查询一下
            [root@k8s-master ~]# kubectl get pods --selector name --label-columns=name
            NAME               READY   STATUS    RESTARTS   AGE    NAME
            mine-nginx-j2zsj   1/1     Running   0          4m4s   mine-nginx
            mine-nginx-k9qcp   1/1     Running   0          4m4s   mine-nginx
            mine-nginx-rrcp4   1/1     Running   0          4m4s   mine-nginx


    创建 service
        1、创建 service 文件, mine-nginx-service.yaml

        2、根据 文件创建 service
            [root@k8s-master ~]# kubectl create -f /home/chapter_06/mine-nginx-service.yaml
            service/mine-nginx created

        3、查询
            [root@k8s-master ~]# kubectl get service mine-nginx
            NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE   SELECTOR
            mine-nginx   ClusterIP   10.100.108.110   <none>        80/TCP    6s    name=mine-nginx

            [root@k8s-master ~]# kubectl describe service mine-nginx
            Name:              mine-nginx
            Namespace:         default
            Labels:            name=mine-nginx
            Annotations:       <none>
            Selector:          name=mine-nginx
            Type:              ClusterIP
            IP:                10.100.108.110
            Port:              <unset>  80/TCP
            TargetPort:        80/TCP
            Endpoints:         10.32.0.2:80,10.34.0.1:80,10.40.0.1:80
            Session Affinity:  None
            Events:            <none>

            [root@k8s-master ~]# kubectl get pods --selector name=mine-nginx -o yaml|grep podIP
                podIP: 10.34.0.1
                podIP: 10.40.0.1
                podIP: 10.32.0.2

        4、根据 Service 分配的 IP 可以在 kubernetes 环境下 使用 curl 连接, master 和 node 节点都可以连接这个 虚拟 IP!
            [root@k8s-master ~]# curl 10.100.108.110

            [root@k8s-node-* ~]# curl 10.100.108.110
            <!DOCTYPE html>
            <html>
            <head>
            <title>Welcome to nginx!</title>
            <style>
            html { color-scheme: light dark; }
            body { width: 35em; margin: 0 auto;
            font-family: Tahoma, Verdana, Arial, sans-serif; }
            </style>
            </head>
            <body>
            <h1>Welcome to nginx!</h1>
            <p>If you see this page, the nginx web server is successfully installed and
            working. Further configuration is required.</p>

            <p>For online documentation and support please refer to
            <a href="http://nginx.org/">nginx.org</a>.<br/>
            Commercial support is available at
            <a href="http://nginx.com/">nginx.com</a>.</p>

            <p><em>Thank you for using nginx.</em></p>
            </body>
            </html>


Service 虚拟IP:

    查询 Service 关联的 pod 的虚拟 IP:
        [root@k8s-master ~]# kubectl get pods --selector name=mine-nginx -o yaml|grep podIP
            podIP: 10.34.0.1
            podIP: 10.40.0.1
            podIP: 10.32.0.2

    查询 service 关联的 pod 的虚拟 IP:
        [root@k8s-master ~]# kubectl describe service mine-nginx
        Name:              mine-nginx
        Namespace:         default
        Labels:            name=mine-nginx
        Annotations:       <none>
        Selector:          name=mine-nginx
        Type:              ClusterIP
        IP:                10.100.108.110
        Port:              <unset>  80/TCP
        TargetPort:        80/TCP
        Endpoints:         10.32.0.2:80,10.34.0.1:80,10.40.0.1:80
        Session Affinity:  None
        Events:            <none>


服务代理:
    Service 的后端服务为 Endpoints, 根据这些 podIP 虚拟出一个 代理地址即 clusterIP

    Service 不仅能够代理 pod, 也能够代理 非kubernetes 服务! Service 代理本地服务 MySQL 案例:
    1、创建 service 文件 和 endpoints 文件, mysql-service.yaml 和 mysql-endpoints.yaml

    2、根据 文件创建 service 和 endpoints
        [root@k8s-master ~]# kubectl create -f /home/chapter_06/mysql-service.yaml -f /home/chapter_06/mysql-endpoints.yaml
        service/mysql created
        endpoints/mysql created

    3、查询 service 和 endpoints
        [root@k8s-master ~]# kubectl get service mysql
        NAME    TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE
        mysql   ClusterIP   10.99.126.2   <none>        3306/TCP   66m

        [root@k8s-master ~]# kubectl get endpoints mysql
        NAME    ENDPOINTS            AGE
        mysql   192.168.124.2:3306   66m

        [root@k8s-master ~]# kubectl describe service mysql
        Name:              mysql
        Namespace:         default
        Labels:            name=mysql
        Annotations:       <none>
        Selector:          <none>
        Type:              ClusterIP
        IP:                10.99.126.2
        Port:              <unset>  3306/TCP
        TargetPort:        3306/TCP
        Endpoints:         192.168.124.2:3306
        Session Affinity:  None
        Events:            <none>

Service 发布:
    对外发布 service 的方式有三种, 参考: 01_kubernetes发布service的方式.png

    NodePortService 进行 service 的发布:
        1、根据 mine-nginx-rc.yaml 创建 replicationcontroller

        2、根据 node-port-service.yaml 创建 NodePortService

        3、查询 service
            [root@k8s-master ~]# kubectl get service --selector name=mine-nginx
            NAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
            mine-nginx   NodePort   10.108.174.144   <none>        80:30001/TCP   5s

        访问方式为:  NodeIP : NodePort
        http://192.168.188.44:30001
        http://192.168.188.46:30001
        http://192.168.188.47:30001
        http://192.168.188.48:30001


    LoadBalancerService 进行 Service 发布:
        1、根据 mine-nginx-rc.yaml 创建 replicationcontroller

        2、根据 node-port-service.yaml 创建 LoadBalancerService

        3、查询 service
            [root@k8s-master ~]# kubectl get service --selector name=mine-nginx
            NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
            mine-nginx   LoadBalancer   10.99.219.177   <pending>     80:31555/TCP   3m24s

        访问方式为:  NodeIP : NodePort
        http://192.168.188.44:31555
        http://192.168.188.46:31555
        http://192.168.188.47:31555
        http://192.168.188.48:31555

    Ingress 进行 Service 发布: 这种比较复杂, 目前不研究, 不如完全交于 kubernetes 处理来的更舒服!


--------------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------- 第7章 数据卷 -------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------
kubernetes 重新定义 数据卷的概念! 从 功能上来说 分为三种: 本地数据卷, 网络数据卷, 信息数据卷!

本地数据卷:
